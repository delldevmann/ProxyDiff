name: Scrape and Compare Proxies

on:
  schedule:
    - cron: '0 */6 * * *'  # Every 6 hours
  workflow_dispatch:

permissions:
  contents: write

jobs:
  compare-proxies:
    runs-on: ubuntu-latest

    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.11'

      - name: Install dependencies
        run: |
          pip install requests pandas

      - name: Scrape and Compare Proxy Lists
        run: |
          python3 <<'EOF'
          import requests, re, os, json
          import pandas as pd
          from datetime import datetime

          # Step 1: Get list of all proxy result files
          base_url = "https://raw.githubusercontent.com/delldevmann/proxy-scraper/refs/heads/main/results/"
          index_url = "https://api.github.com/repos/delldevmann/proxy-scraper/contents/results"
          headers = {"Accept": "application/vnd.github.v3+json"}

          result = requests.get(index_url, headers=headers).json()
          proxy_files = [item['name'] for item in result if item['name'].startswith("all_proxies_") and item['name'].endswith(".json")]

          def extract_timestamp(name):
              match = re.search(r'all_proxies_(\d{8}_\d{6})\.json', name)
              return datetime.strptime(match.group(1), "%Y%m%d_%H%M%S") if match else datetime.min

          proxy_files.sort(key=extract_timestamp)

          proxies_by_snapshot = {}
          for fname in proxy_files:
              url = base_url + fname
              try:
                  snap = extract_timestamp(fname).isoformat()
                  content = requests.get(url).json()
                  proxies_by_snapshot[snap] = set(content.keys())
              except Exception as e:
                  print(f"Error loading {fname}: {e}")

          snapshots = sorted(proxies_by_snapshot.keys())
          if len(snapshots) < 2:
              print("Not enough snapshots to compare.")
              exit(0)

          latest = proxies_by_snapshot[snapshots[-1]]
          previous = proxies_by_snapshot[snapshots[-2]]

          new_proxies = latest - previous
          dropped_proxies = previous - latest
          retained_proxies = latest & previous

          os.makedirs("proxy-diff", exist_ok=True)
          summary = {
              "new": list(new_proxies),
              "dropped": list(dropped_proxies),
              "retained": list(retained_proxies),
              "latest_snapshot": snapshots[-1],
              "previous_snapshot": snapshots[-2]
          }

          with open("proxy-diff/diff_summary.json", "w") as f:
              json.dump(summary, f, indent=2)

          df = pd.DataFrame({
              "Proxy": list(latest | previous),
              "Status": ["new" if p in new_proxies else "dropped" if p in dropped_proxies else "retained" for p in (latest | previous)]
          })
          df.to_csv("proxy-diff/diff_report.csv", index=False)
          print(df.value_counts("Status"))
          EOF

      - name: Commit diff summary
        run: |
          git config --global user.name "github-actions"
          git config --global user.email "github-actions@users.noreply.github.com"
          git add proxy-diff/*
          git commit -m "Update proxy diff report" || echo "No changes to commit"
          git push
